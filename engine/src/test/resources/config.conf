#Print streams in each spark iteration
printStreams = true

#Enable stats
statsEnabled = false
	
#Save all actions realized on the platform
auditEnabled = false
	
#Save all data into cassandra periodically
failover = {
	enabled = true
	period = 10 s
}

kafka = {
	hosts = ["localhost:29092"]
	connectionTimeout = 10000
	sessionTimeout = 10000
	
	# default replication factor and partitions for internal topics
	replicationFactor = 1
	partitions = 1
}
zookeeper = {
	hosts = ["localhost:22181"]
}
spark = {
	internalHost = "local[6]"
	internalStreamingBatchTime = 2 s
	
	host ="local[6]"
	streamingBatchTime = 2 s
}
cassandra = {
	hosts = ["localhost"]
}
mongo = {
	hosts = ["localhost:227017"]
	#username = ""
	#password= ""
}
elasticsearch = {
	hosts = ["localhost:29300"]
	clusterName = "elasticsearch"
}

solr = {
	hosts = "localhost:22181"
	cloud = true
	dataDir = "/tmp/streaming-solr"
}

drools = {
	host = "drools.server.inet:1234"
	username = "xxxx"
	password = "xxxx"
	batchSize = 500
	mappingLibraryDir = "/etc/sds/decision/mapping"
}

